{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# \uc5f0\uad6c\uc790\uc5d0\uac8c \ub9de\ub294 \ucf00\ub77c\uc2a4 \uc18c\uac1c\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2020/04/01<br>\n",
    "**Last modified:** 2020/04/28<br>\n",
    "**Description:** \ucf00\ub77c\uc2a4\uc640 TF 2.0\uc73c\ub85c \ub525\ub7ec\ub2dd \uc5f0\uad6c\ub97c \ud558\uae30 \uc704\ud574 \uc54c\uc544\uc57c \ud560 \ubaa8\ub4e0 \uac83."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uc124\uc815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uc18c\uac1c\n",
    "\n",
    "\uba38\uc2e0\ub7ec\ub2dd \uc5f0\uad6c\uc790\uc778\uac00\uc694?\n",
    "NeurIPS\uc5d0 \ub17c\ubb38\uc744 \uc81c\ucd9c\ud558\uace0 \ucef4\ud4e8\ud130 \ube44\uc804\uc774\ub098 \uc790\uc5f0\uc5b4 \ucc98\ub9ac \ubd84\uc57c\uc5d0\uc11c \ucd5c\uace0\uc758 \uc131\ub2a5\uc744 \ub2ec\uc131\ud558\ub824\uace0 \ud558\ub098\uc694?\n",
    "\uc774 \uac00\uc774\ub4dc\uc5d0\uc11c \ucf00\ub77c\uc2a4 API\uc758 \ud575\uc2ec \uac1c\ub150\uc744 \uc18c\uac1c\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\uc774 \uac00\uc774\ub4dc\uc5d0\uc11c \ub2e4\uc74c \ub0b4\uc6a9\uc744 \ubc30\uc6b8 \uc218 \uc788\uc2b5\ub2c8\ub2e4:\n",
    "\n",
    "- `Layer` \ud074\ub798\uc2a4\ub97c \uc0c1\uc18d\ud558\uc5ec \uce35\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "- `GradientTape`\uc73c\ub85c \uadf8\ub808\uc774\ub514\uc5b8\ud2b8(gradient)\ub97c \uacc4\uc0b0\ud558\uace0 \uc800\uc218\uc900 \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "- `add_loss()` \uba54\uc11c\ub4dc\ub85c \uce35\uc5d0\uc11c \ub9cc\ub4e0 \uc190\uc2e4\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
    "- \uc800\uc218\uc900 \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc5d0\uc11c \uce21\uc815 \uc9c0\ud45c\ub97c \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
    "- `tf.function`\uc73c\ub85c \ucef4\ud30c\uc77c\ud558\uc5ec \uc2e4\ud589 \uc18d\ub3c4\ub97c \ub192\uc785\ub2c8\ub2e4.\n",
    "- \ud6c8\ub828 \ubaa8\ub4dc\ub098 \ucd94\ub860 \ubaa8\ub4dc\ub85c \uce35\uc744 \uc2e4\ud589\ud569\ub2c8\ub2e4.\n",
    "- \ucf00\ub77c\uc2a4 \ud568\uc218\ud615 API\n",
    "\n",
    "\ubcc0\uc774\ud615 \uc624\ud1a0\uc778\ucf54\ub354(Variational Autoencoder)\uc640 \ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c(Hypernetwork)\n",
    "\ub450 \uac1c\uc758 \uc5d4\ub4dc-\ud22c-\uc5d4\ub4dc \uc5f0\uad6c \uc608\uc81c \ud1b5\ud574 \uc2e4\uc81c\ub85c \ucf00\ub77c\uc2a4 API\ub97c \uc0ac\uc6a9\ud574 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## `Layer` \ud074\ub798\uc2a4\n",
    "\n",
    "`Layer`\ub294 \ucf00\ub77c\uc2a4\uc758 \uae30\ucd08 \ucd94\uc0c1 \ud074\ub798\uc2a4\uc785\ub2c8\ub2e4.\n",
    "`Layer`\ub294 \uc0c1\ud0dc(\uac00\uc911\uce58)\uc640 (`call` \uba54\uc11c\ub4dc\uc5d0\uc11c \uc815\uc758\ud55c) \uc77c\ubd80 \uacc4\uc0b0\uc744 \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\uac04\ub2e8\ud55c \uce35\uc758 \uc608\ub294 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Linear(keras.layers.Layer):\n",
    "    \"\"\"y = w.x + b\"\"\"\n",
    "\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Linear, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value=w_init(shape=(input_dim, units), dtype=\"float32\"),\n",
    "            trainable=True,\n",
    "        )\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.b = tf.Variable(\n",
    "            initial_value=b_init(shape=(units,), dtype=\"float32\"), trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "`Layer` \ud074\ub798\uc2a4 \uc778\uc2a4\ud134\uc2a4\ub97c \ud30c\uc774\uc36c \ud568\uc218\ucc98\ub7fc \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uce35\uc758 \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "linear_layer = Linear(units=4, input_dim=2)\n",
    "\n",
    "# \ud568\uc218\ucc98\ub7fc \uc0ac\uc6a9\ud598 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "# `call` \uba54\uc11c\ub4dc\uc5d0 \ud544\uc694\ud55c \ub370\uc774\ud130\ub97c \uc804\ub2ec\ud558\uba74\uc11c \ud638\ucd9c\ud569\ub2c8\ub2e4.\n",
    "y = linear_layer(tf.ones((2, 2)))\n",
    "assert y.shape == (2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "(`__init__` \uba54\uc11c\ub4dc\uc5d0\uc11c \uc0dd\uc131\ud55c) \uac00\uc911\uce58 \ubcc0\uc218\ub294 \uc790\ub3d9\uc73c\ub85c `weights` \uc18d\uc131\uc5d0 \uae30\ub85d\ub429\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "assert linear_layer.weights == [linear_layer.w, linear_layer.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uae30\ubcf8\uc73c\ub85c \ub0b4\uc7a5\ub41c \uce35\uc774 \ub9ce\uc2b5\ub2c8\ub2e4.\n",
    "`Dense` \uce35, `Conv2D` \uce35, `LSTM` \uce35\uc774 \uc788\uace0\n",
    "`Conv3DTranspose`\uc774\ub098 `ConvLSTM2D`\uc640 \uac19\uc740 \ud654\ub824\ud55c \uce35\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uac00\ub2a5\ud558\uba74 \ub0b4\uc7a5\ub41c \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uac00\uc911\uce58 \uc0dd\uc131\n",
    "\n",
    "`add_weight` \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uba74 \uc190\uc27d\uac8c \uac00\uc911\uce58\ub97c \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Linear(keras.layers.Layer):\n",
    "    \"\"\"y = w.x + b\"\"\"\n",
    "\n",
    "    def __init__(self, units=32):\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "\n",
    "# \uce35\uc758 \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "linear_layer = Linear(4)\n",
    "\n",
    "# `build(input_shape)`\uc744 \ud638\ucd9c\ud558\uace0 \uac00\uc911\uce58\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "y = linear_layer(tf.ones((2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\n",
    "\n",
    "`GradientTape` \ucee8\ud0dd\uc2a4\ud2b8 \uc548\uc5d0\uc11c \uce35\uc744 \ud638\ucd9c\ud558\uba74 \uc790\ub3d9\uc73c\ub85c \uce35 \uac00\uc911\uce58\uc758 \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "\uc774 \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uc0ac\uc6a9\ud574 \uc635\ud2f0\ub9c8\uc774\uc800 \uac1d\uccb4\ub97c \uc0ac\uc6a9\ud558\uac70\ub098 \uc218\ub3d9\uc73c\ub85c \uce35\uc758 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\ubb3c\ub860 \ud544\uc694\ud558\uba74 \uc5c5\ub370\uc774\ud2b8\ud558\uae30 \uc804\uc5d0 \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uc218\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype(\"float32\") / 255, y_train)\n",
    ")\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# 10\uac1c\uc758 \uc720\ub2db(unit)\uc744 \uac00\uc9c4 (\uc704\uc5d0\uc11c \uc815\uc758\ud55c) \uc120\ud615 \uce35\uc758 \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "linear_layer = Linear(10)\n",
    "\n",
    "# \uc815\uc218 \ud0c0\uae43\uc744 \uae30\ub300\ud558\ub294 \ub85c\uc9c0\uc2a4\ud2f1 \uc190\uc2e4 \ud568\uc218 \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "# \uc635\ud2f0\ub9c8\uc774\uc800 \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc758 \ubc30\uce58\ub97c \uc21c\ud68c\ud569\ub2c8\ub2e4.\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "\n",
    "    # GradientTape\uc744 \uc2dc\uc791\ud569\ub2c8\ub2e4.\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # \uc815\ubc29\ud5a5 \uacc4\uc0b0\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n",
    "        logits = linear_layer(x)\n",
    "\n",
    "        # \ubc30\uce58\uc758 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "        loss = loss_fn(y, logits)\n",
    "\n",
    "    # \uc190\uc2e4\uc5d0 \ub300\ud55c \uac00\uc911\uce58\uc758 \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\n",
    "    gradients = tape.gradient(loss, linear_layer.trainable_weights)\n",
    "\n",
    "    # \uc120\ud615 \uce35\uc758 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n",
    "    optimizer.apply_gradients(zip(gradients, linear_layer.trainable_weights))\n",
    "\n",
    "    # \ub85c\uae45\n",
    "    if step % 100 == 0:\n",
    "        print(\"\uc2a4\ud15d:\", step, \"\uc190\uc2e4:\", float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \ud6c8\ub828\ub418\ub294 \uac00\uc911\uce58\uc640 \ud6c8\ub828 \uc548\ub418\ub294 \uac00\uc911\uce58\n",
    "\n",
    "\uce35\uc740 \ud6c8\ub828\ub418\ub294 \uac00\uc911\uce58 \ub610\ub294 \ud6c8\ub828 \uc548\ub418\ub294 \uac00\uc911\uce58\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "\uac01\uac01 `trainable_weights`\uc640 `non_trainable_weights` \uc18d\uc131\uc73c\ub85c \ucc38\uc870\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\ub2e4\uc74c\uc740 \ud6c8\ub828 \uc548\ub418\ub294 \uac00\uc911\uce58\ub97c \uac00\uc9c4 \uce35\uc785\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ComputeSum(keras.layers.Layer):\n",
    "    \"\"\"\uc785\ub825\uc758 \ud569\uc744 \ubc18\ud658\ud569\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super(ComputeSum, self).__init__()\n",
    "        # Create a non-trainable weight.\n",
    "        self.total = tf.Variable(initial_value=tf.zeros((input_dim,)), trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.total.assign_add(tf.reduce_sum(inputs, axis=0))\n",
    "        return self.total\n",
    "\n",
    "\n",
    "my_sum = ComputeSum(2)\n",
    "x = tf.ones((2, 2))\n",
    "\n",
    "y = my_sum(x)\n",
    "print(y.numpy())  # [2. 2.]\n",
    "\n",
    "y = my_sum(x)\n",
    "print(y.numpy())  # [4. 4.]\n",
    "\n",
    "assert my_sum.weights == [my_sum.total]\n",
    "assert my_sum.non_trainable_weights == [my_sum.total]\n",
    "assert my_sum.trainable_weights == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uce35\uc744 \uac00\uc9c4 \uce35\n",
    "\n",
    "\uce35\uc740 \uc7ac\uadc0\uc801\uc73c\ub85c \uc911\ucca9\ub418\uc5b4 \ub354 \ud070 \uc5f0\uc0b0 \ube14\ub85d\uc744 \uad6c\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uac01 \uce35\uc740 \ud558\uc704 \uce35\uc758 \uac00\uc911\uce58\ub97c \ud0d0\uc0c9\ud569\ub2c8\ub2e4(\ud6c8\ub828\ub418\ub294 \uac00\uc911\uce58\uc640 \ud6c8\ub828 \uc548\ub418\ub294 \uac00\uc911\uce58 \ubaa8\ub450)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uc704\uc5d0\uc11c \uc815\uc758\ud55c `build` \uba54\uc11c\ub4dc\ub97c \uac00\uc9c4\n",
    "# Linear \ud074\ub798\uc2a4\ub97c \uc7ac\uc0ac\uc6a9\ud574 \ubcf4\uc8e0.\n",
    "\n",
    "\n",
    "class MLP(keras.layers.Layer):\n",
    "    \"\"\"Linear \uce35\uc744 \ub2e8\uc21c\ud558\uac8c \uc313\uc2b5\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.linear_2 = Linear(32)\n",
    "        self.linear_3 = Linear(10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return self.linear_3(x)\n",
    "\n",
    "\n",
    "mlp = MLP()\n",
    "\n",
    "# \ucc98\uc74c `mlp` \uac1d\uccb4\ub97c \ud638\ucd9c\ud558\uba74 \uac00\uc911\uce58\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "y = mlp(tf.ones(shape=(3, 64)))\n",
    "\n",
    "# \uc7ac\uadc0\uc801\uc73c\ub85c \uac00\uc911\uce58\ub97c \ud0d0\uc0c9\ud569\ub2c8\ub2e4.\n",
    "assert len(mlp.weights) == 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc704\uc5d0\uc11c \uc9c1\uc811 \ub9cc\ub4e0 MLP \ud074\ub798\uc2a4\ub294 \ub2e4\uc74c\ucc98\ub7fc \ub0b4\uc7a5\ub41c \ud074\ub798\uc2a4\ub85c \ub9cc\ub4e0 \uac83\uacfc \ub3d9\uc77c\ud569\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "mlp = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uce35\uc774 \ub9cc\ub4e0 \uc190\uc2e4 \ud0d0\uc0c9\ud558\uae30\n",
    "\n",
    "\uce35\uc740 \uc815\ubc29\ud5a5 \uacc4\uc0b0 \ub3d9\uc548 `add_loss()` \uba54\uc11c\ub4dc\ub85c \uc190\uc2e4\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\ud2b9\ud788 \uaddc\uc81c \uc190\uc2e4\uc744 \ub2e4\ub8f0 \ub54c \uc720\uc6a9\ud569\ub2c8\ub2e4.\n",
    "\ud558\uc704 \uce35\uc774 \ub9cc\ub4e0 \uc190\uc2e4\uc740 \ubd80\ubaa8 \uce35\uc774 \uc7ac\uadc0\uc801\uc73c\ub85c \ud0d0\uc0c9\ud569\ub2c8\ub2e4.\n",
    "Layers can create losses during the forward pass via the `add_loss()` method.\n",
    "This is especially useful for regularization losses.\n",
    "The losses created by sublayers are recursively tracked by the parent layers.\n",
    "\n",
    "\ud65c\uc131\ud654 \uaddc\uc81c \uc190\uc2e4\uc744 \ub9cc\ub4dc\ub294 \uce35\uc785\ub2c8\ub2e4:Here's a layer that creates an activity regularization loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ActivityRegularization(keras.layers.Layer):\n",
    "    \"\"\"\ud65c\uc131\ud654 \ud76c\uc18c \uaddc\uc81c \uc190\uc2e4\uc744 \ub9cc\ub4dc\ub294 \uce35\uc785\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self, rate=1e-2):\n",
    "        super(ActivityRegularization, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # `add_loss`\ub97c \uc0ac\uc6a9\ud574 \uc785\ub825\uc5d0 \uae30\ubc18\ud55c \uaddc\uc81c \uc190\uc2e4\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "        self.add_loss(self.rate * tf.reduce_sum(inputs))\n",
    "        return inputs\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc774 \uce35\uc744 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub4e0 \ubaa8\ub378\uc740 \uc774 \uaddc\uc81c \uc190\uc2e4\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# MLP \ube14\ub85d\uc5d0 \uc774 \uc190\uc2e4 \uce35\uc744 \uc0ac\uc6a9\ud574 \ubcf4\uc8e0.\n",
    "\n",
    "\n",
    "class SparseMLP(keras.layers.Layer):\n",
    "    \"\"\"\ud76c\uc18c \uaddc\uc81c \uc190\uc2e4\uc744 \uc0ac\uc6a9\ud558\uace0 Linear \uce35\uc744 \uc313\uc740 \ubaa8\ub378.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SparseMLP, self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.regularization = ActivityRegularization(1e-2)\n",
    "        self.linear_3 = Linear(10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.regularization(x)\n",
    "        return self.linear_3(x)\n",
    "\n",
    "\n",
    "mlp = SparseMLP()\n",
    "y = mlp(tf.ones((10, 10)))\n",
    "\n",
    "print(mlp.losses)  # \ud558\ub098\uc758 float32 \uc2a4\uce7c\ub77c\ub97c \ub2f4\uc740 \ub9ac\uc2a4\ud2b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc774 \uc190\uc2e4\uc740 \uc815\ubc29\ud5a5 \uacc4\uc0b0\uc774 \uc2dc\uc791\ub420 \ub54c\ub9c8\ub2e4 \ucd5c\uc0c1\uc704 \uce35\uc5d0 \uc758\ud574 \ucd08\uae30\ud654\ub429\ub2c8\ub2e4. \uc989 \ub204\uc801\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n",
    "`layer.losses`\ub294 \ud56d\uc0c1 \ub9c8\uc9c0\ub9c9 \uc815\ubc29\ud5a5 \uacc4\uc0b0\uc5d0\uc11c \ub9cc\ub4e0 \uc190\uc2e4\ub9cc \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uc77c\ubc18\uc801\uc73c\ub85c \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc744 \ub9cc\ub4e4 \ub54c \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uacc4\uc0b0\ud558\uae30 \uc804\uc5d0 \uc774 \uc190\uc2e4\uc744 \ub354\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# *\ub9c8\uc9c0\ub9c9* \uc815\ubc29\ud5a5 \uacc4\uc0b0\uc758 \uc190\uc2e4\uc774 \uc800\uc7a5\ub429\ub2c8\ub2e4.\n",
    "mlp = SparseMLP()\n",
    "mlp(tf.ones((10, 10)))\n",
    "assert len(mlp.losses) == 1\n",
    "mlp(tf.ones((10, 10)))\n",
    "assert len(mlp.losses) == 1  # \ub204\uc801\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "# \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc5d0\uc11c \uc5b4\ub5bb\uac8c \uc774 \uc190\uc2e4\uc744 \uc0ac\uc6a9\ud558\ub294\uc9c0 \uc54c\uc544\ubcf4\uc8e0.\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype(\"float32\") / 255, y_train)\n",
    ")\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# \uc0c8\ub85c\uc6b4 MLP\n",
    "mlp = SparseMLP()\n",
    "\n",
    "# \uc190\uc2e4\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # \uc815\ubc29\ud5a5 \uacc4\uc0b0\n",
    "        logits = mlp(x)\n",
    "\n",
    "        # \uc774 \ubc30\uce58\uc5d0 \ub300\ud55c \uc678\ubd80 \uc190\uc2e4 \uac12\n",
    "        loss = loss_fn(y, logits)\n",
    "\n",
    "        # \uc815\ubc29\ud5a5 \uacc4\uc0b0 \ub3d9\uc548 \ub9cc\ub4e4\uc5b4\uc9c4 \uc190\uc2e4\uc744 \ub354\ud569\ub2c8\ub2e4.\n",
    "        loss += sum(mlp.losses)\n",
    "\n",
    "        # \uc190\uc2e4\uc5d0 \ub300\ud55c \uac00\uc911\uce58\uc758 \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uad6c\ud569\ub2c8\ub2e4.\n",
    "        gradients = tape.gradient(loss, mlp.trainable_weights)\n",
    "\n",
    "    # \uc120\ud615 \uce35\uc758 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n",
    "    optimizer.apply_gradients(zip(gradients, mlp.trainable_weights))\n",
    "\n",
    "    # \ub85c\uae45.\n",
    "    if step % 100 == 0:\n",
    "        print(\"\uc2a4\ud15d:\", step, \"\uc190\uc2e4:\", float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \ud6c8\ub828 \uc9c0\ud45c \uae30\ub85d\ud558\uae30\n",
    "\n",
    "\ucf00\ub77c\uc2a4\ub294 `tf.keras.metrics.AUC`\ub098 `tf.keras.metrics.PrecisionAtRecall` \uac19\uc774\n",
    "\ub2e4\uc591\ud55c \uce21\uc815 \uc9c0\ud45c\ub97c \uae30\ubcf8\uc73c\ub85c \uc81c\uacf5\ud569\ub2c8\ub2e4.\n",
    "\uba87 \uc904\uc758 \ucf54\ub4dc\ub85c \uc0ac\uc6a9\uc790 \uc815\uc758 \uc9c0\ud45c\ub97c \uc27d\uac8c \ub9cc\ub4e4 \uc218\ub3c4 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\uc0ac\uc6a9\uc790 \uc815\uc758 \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc5d0\uc11c \uc9c0\ud45c\ub97c \uc0ac\uc6a9\ud558\ub294 \ubc29\ubc95\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n",
    "\n",
    "- \uce21\uc815 \uc9c0\ud45c \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4. \uc608\ub97c \ub4e4\uba74 `metric = tf.keras.metrics.AUC()`\n",
    "- \uac01 \ubc30\uce58 \ub370\uc774\ud130\uc5d0 \ub300\ud574 `metric.udpate_state(targets, predictions)` \uba54\uc11c\ub4dc\ub97c \ud638\ucd9c\ud569\ub2c8\ub2e4.\n",
    "- `metric.result()`\ub85c \uacb0\uacfc\ub97c \uc5bb\uc2b5\ub2c8\ub2e4.\n",
    "- `metric.reset_states()`\ub97c \uc0ac\uc6a9\ud574 \uc5d0\ud3ec\ud06c \ub05d\uc774\ub098 \ud3c9\uac00\ub97c \uc2dc\uc791\ud560 \ub54c \uc9c0\ud45c\uc758 \uc0c1\ud0dc\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n",
    "\n",
    "\ub2e4\uc74c\uc740 \uac04\ub2e8\ud55c \uc608\uc785\ub2c8\ub2e4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uce21\uc815 \uc9c0\ud45c \uac1d\uccb4\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "# \uce35, \uc190\uc2e4, \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "for epoch in range(2):\n",
    "    # \ub370\uc774\ud130\uc14b\uc758 \ubc30\uce58\uc5d0 \ub300\ud574 \ubc18\ubcf5\ud569\ub2c8\ub2e4.\n",
    "    for step, (x, y) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            # \uc774 \ubc30\uce58\uc758 \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "            loss_value = loss_fn(y, logits)\n",
    "\n",
    "        # `accuracy` \uc9c0\ud45c\uc758 \uc0c1\ud0dc\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n",
    "        accuracy.update_state(y, logits)\n",
    "\n",
    "        # \uc190\uc2e4 \uac12\uc744 \ucd5c\uc18c\ud654\ud558\uae30 \uc704\ud574 \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n",
    "        gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "        # \ud604\uc7ac \uc815\ud655\ub3c4 \uac12\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
    "        if step % 200 == 0:\n",
    "            print(\"\uc5d0\ud3ec\ud06c:\", epoch, \"\uc2a4\ud15d:\", step)\n",
    "            print(\"\uc9c0\uae08\uae4c\uc9c0 \uacc4\uc0b0\ud55c \uc804\uccb4 \uc815\ud655\ub3c4: %.3f\" % accuracy.result())\n",
    "\n",
    "    # \uc5d0\ud3ec\ud06c \ub05d\uc5d0\uc11c \uc9c0\ud45c\uc758 \uc0c1\ud0dc\ub97c \ucd08\uae30\ud654\ud569\ub2c8\ub2e4.\n",
    "    accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ub610\ud55c `self.add_loss()` \uba54\uc11c\ub4dc\uc640 \ube44\uc2b7\ud558\uac8c \uce35\uc5d0\uc11c `self.add_metric()` \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uc774 \uba54\uc11c\ub4dc\ub294 \uc804\ub2ec\ud55c \uac12\uc758 \ud3c9\uade0\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "\uce35\uc774\ub098 \ubaa8\ub378\uc758 `layer.reset_metrics()` \uba54\uc11c\ub4dc\ub97c \ud638\ucd9c\ud558\uc5ec \ucd08\uae30\ud654\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \ucef4\ud30c\uc77c\ub41c \ud568\uc218\n",
    "\n",
    "\uc989\uc2dc \uc2e4\ud589\uc740 \ub514\ubc84\uae45\uc5d0 \uc88b\uc9c0\ub9cc \uc815\uc801 \uadf8\ub798\ud504\ub85c \ucef4\ud30c\uc77c\ud558\uba74 \ub354 \ub192\uc740 \uc131\ub2a5\uc744 \uc5bb\uc744 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uc815\uc801 \uadf8\ub798\ud504\ub294 \uc5f0\uad6c\uc790\uc5d0\uac8c \uc548\uc131\ub9de\ucda4\uc785\ub2c8\ub2e4.\n",
    "`tf.function` \ub370\ucf54\ub808\uc774\ud130\ub85c \uac10\uc2f8\uba74 \uc5b4\ub5a4 \ud568\uc218\ub3c4 \ucef4\ud30c\uc77c\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uce35, \uc190\uc2e4, \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(32, activation=\"relu\"),\n",
    "        keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# \ud6c8\ub828 \uc2a4\ud15d \ud568\uc218\ub97c \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "\n",
    "\n",
    "@tf.function  # \uc18d\ub3c4\ub97c \ub192\uc785\ub2c8\ub2e4.\n",
    "def train_on_batch(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(y, logits)\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype(\"float32\") / 255, y_train)\n",
    ")\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    loss = train_on_batch(x, y)\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step:\", step, \"Loss:\", float(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \ud6c8\ub828 \ubaa8\ub4dc & \ucd94\ub860 \ubaa8\ub4dc\n",
    "\n",
    "`BatchNormalization`\uacfc `Dropout` \uac19\uc740 \uc77c\ubd80 \uce35\uc740 \ud6c8\ub828\uacfc \ucd94\ub860 \uc2dc\uc5d0 \ud589\ub3d9\uc774 \ub2e4\ub985\ub2c8\ub2e4.\n",
    "\uc774\ub7f0 \uce35\uc744 \uc0ac\uc6a9\ud560 \ub54c\ub294 `call` \uba54\uc11c\ub4dc\uc5d0 `training` (\ubd88\ub9ac\uc5b8) \ub9e4\uac1c\ubcc0\uc218\ub97c \uc9c0\uc815\ud558\ub294 \uac83\uc774 \uc88b\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "`call` \uba54\uc11c\ub4dc\uc5d0 \uc774 \ub9e4\uac1c\ubcc0\uc218\ub97c \uc9c0\uc815\ud558\uba74 \ucf00\ub77c\uc2a4\uac00 \uae30\ubcf8\uc73c\ub85c \uc81c\uacf5\ud558\ub294\n",
    "\ud6c8\ub828\uacfc \ud3c9\uac00 \ubc18\ubcf5\uc744 \uc0ac\uc6a9\ud560 \uc218 \uc788\uace0(\uc608\ub97c \ub4e4\uc5b4 `fit` \uba54\uc11c\ub4dc),\n",
    "\ud6c8\ub828\uacfc \ucd94\ub860 \ubaa8\ub4dc\ub85c \uce35\uc744 \uc0ac\uc6a9\ud560 \ub54c \uc624\ub958\ub97c \uc904\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dropout(keras.layers.Layer):\n",
    "    def __init__(self, rate):\n",
    "        super(Dropout, self).__init__()\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return tf.nn.dropout(inputs, rate=self.rate)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class MLPWithDropout(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLPWithDropout, self).__init__()\n",
    "        self.linear_1 = Linear(32)\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.linear_3 = Linear(10)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return self.linear_3(x)\n",
    "\n",
    "\n",
    "mlp = MLPWithDropout()\n",
    "y_train = mlp(tf.ones((2, 2)), training=True)\n",
    "y_test = mlp(tf.ones((2, 2)), training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \ud568\uc218\ud615 API\ub97c \uc0ac\uc6a9\ud55c \ubaa8\ub378 \uad6c\uc131\n",
    "\n",
    "\ub525\ub7ec\ub2dd \ubaa8\ub378\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574 \ud56d\uc0c1 \uac1d\uccb4\uc9c0\ud5a5 \ud504\ub85c\uadf8\ub798\ubc0d\uc744 \uc0ac\uc6a9\ud560 \ud544\uc694\ub294 \uc5c6\uc2b5\ub2c8\ub2e4.\n",
    "\uc9c0\uae08\uae4c\uc9c0 \uc18c\uac1c\ud55c \ubaa8\ub4e0 \uce35\uc740 \ub2e4\uc74c\uacfc \uac19\uc740 \ud568\uc218 \uc2a4\ud0c0\uc77c\ub85c \uc0ac\uc6a9\ud560 \uc218\n",
    "\uc788\uc2b5\ub2c8\ub2e4(\uc774\ub97c \"\ud568\uc218\ud615(Functional) API\"\ub77c\uace0 \ubd80\ub985\ub2c8\ub2e4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# `Input` \uac1d\uccb4\ub97c \uc0ac\uc6a9\ud574 \uc785\ub825\uc758 \ud06c\uae30\uc640 \ub370\uc774\ud130 \ud0c0\uc785\uc744 \uae30\uc220\ud569\ub2c8\ub2e4.\n",
    "# \ub525\ub7ec\ub2dd\uc5d0\uc11c \ud558\ub098\uc758 \"\ud0c0\uc785\"\uc744 \uc815\uc758\ud558\ub294 \uac83\uacfc \uac19\uc2b5\ub2c8\ub2e4.\n",
    "# shape \ub9e4\uac1c\ubcc0\uc218\ub294 \uc0d8\ud50c \ub2e8\uc704\uc785\ub2c8\ub2e4. \uc989 \ubc30\uce58 \ud06c\uae30\ub294 \ud3ec\ud568\ud558\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n",
    "# \ud568\uc218\ud615 API\ub294 \uc0d8\ud50c \ub2e8\uc704\uc758 \ubcc0\ud658\uc744 \uc815\uc758\ud558\ub294\ub370 \ucd08\uc810\uc744 \ub9de\ucda5\ub2c8\ub2e4.\n",
    "# \ub9cc\ub4e4\uc5b4\uc9c4 \ubaa8\ub378\uc740 \uc790\ub3d9\uc73c\ub85c \uc0d8\ud50c \ub2e8\uc704\uc758 \ubcc0\ud658\uc744 \ubc30\uce58\ub85c \uc218\ud589\ud558\uae30 \ub54c\ubb38\uc5d0\n",
    "# \ubc30\uce58 \ub370\uc774\ud130\uc5d0\uc11c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "inputs = tf.keras.Input(shape=(16,), dtype=\"float32\")\n",
    "\n",
    "# \uc774 \"\ud0c0\uc785\" \uac1d\uccb4\ub85c \uce35\uc744 \ud638\ucd9c\ud558\uba74\n",
    "# \uc5c5\ub370\uc774\ud2b8\ub41c \ud0c0\uc785\uc774 \ubc18\ud658\ub429\ub2c8\ub2e4(\uc0c8\ub85c\uc6b4 \ud06c\uae30\uc640 \ub370\uc774\ud130 \ud0c0\uc785).\n",
    "x = Linear(32)(inputs)  # \uc55e\uc11c \uc815\uc758\ud55c Linear \uce35\uc744 \uc7ac\uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n",
    "x = Dropout(0.5)(x)  # \uc55e\uc11c \uc815\uc758\ud55c Linear \uce35\uc744 \uc7ac\uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n",
    "outputs = Linear(10)(x)\n",
    "\n",
    "# \uc785\ub825\uacfc \ucd9c\ub825\uc744 \uc9c0\uc815\ud558\uc5ec \ud568\uc218\ud615 `Model`\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n",
    "# \ubaa8\ub378 \uc790\uccb4\ub294 \ub2e4\ub978 \uac83\uacfc \uac19\uc740 \uce35\uc785\ub2c8\ub2e4.\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# \ud568\uc218\ud615 \ubaa8\ub378\uc740 \ub370\uc774\ud130\uc5d0 \ud638\ucd9c\ud558\uae30 \uc804\uc5d0 \uc774\ubbf8 \uac00\uc911\uce58\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "# \ubbf8\ub9ac \uc785\ub825 \ud06c\uae30\ub97c (`Input`\uc5d0) \uc9c0\uc815\ud588\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4.\n",
    "assert len(model.weights) == 4\n",
    "\n",
    "# \uc2dc\ud5d8 \uc0bc\uc544 \uc0d8\ud50c \ub370\uc774\ud130\uc5d0 \ubaa8\ub378\uc744 \ud638\ucd9c\ud574 \ubcf4\uc8e0.\n",
    "y = model(tf.ones((2, 16)))\n",
    "assert y.shape == (2, 10)\n",
    "\n",
    "# `__call__` \uba54\uc11c\ub4dc\uc758 `training` \ub9e4\uac1c\ubcc0\uc218\ub97c \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4\n",
    "# (`Dropout` \uce35\uc73c\ub85c \ub9e4\uac1c\ubcc0\uc218\uac00 \uc804\ub2ec\ub429\ub2c8\ub2e4).\n",
    "y = model(tf.ones((2, 16)), training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ud568\uc218\ud615 API\ub294 \uc11c\ube0c\ud074\ub798\uc2f1\ubcf4\ub2e4 \uac04\uacb0\ud558\uace0 \uba87\uac00\uc9c0 \ub2e4\ub978 \uc7a5\uc810\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4(\uc77c\ubc18\uc801\uc73c\ub85c\n",
    "\ud0c0\uc785\uc774 \uc5c6\ub294 \uac1d\uccb4\uc9c0\ud5a5 \uac1c\ubc1c\uc5d0 \ube44\ud574 \ud0c0\uc785\uc774 \uc788\ub294 \ud568\uc218\ud615 \uc5b8\uc5b4\uc758 \uc7a5\uc810\uacfc \ub3d9\uc77c\ud569\ub2c8\ub2e4).\n",
    "\ud558\uc9c0\ub9cc \uc720\ud5a5 \ube44\uc21c\ud658 \uadf8\ub798\ud504(directed acyclic graph, DAG)\ub85c \uc815\uc758\ud558\ub294 \uce35\uc5d0\ub9cc \uc0ac\uc6a9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uc21c\ud658 \uc2e0\uacbd\ub9dd\uc740 \uc11c\ube0c\ud074\ub798\uc2f1 \uce35\uc73c\ub85c \uc815\uc758\ud574\uc57c \ud569\ub2c8\ub2e4.\n",
    "\n",
    "\ud568\uc218\ud615 API\uc5d0 \ub300\ud55c \ub354 \uc790\uc138\ud55c \ub0b4\uc6a9\uc740 [\uc5ec\uae30\ub97c](/guides/functional_api/) \ucc38\uace0\ud558\uc138\uc694.\n",
    "\n",
    "\uc5f0\uad6c\uc758 \uc791\uc5c5 \ud750\ub984\uc5d0 \ub530\ub77c \uac1d\uccb4\uc9c0\ud5a5 \ubaa8\ub378\uacfc \ud568\uc218\ud615 \ubaa8\ub378\uc744 \uc785\ub9db\uc5d0 \ub9de\uac8c \uc11e\uc5b4 \uc4f8 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "`Model` \ud074\ub798\uc2a4\ub294 \uae30\ubcf8\uc801\uc73c\ub85c \ud6c8\ub828\uacfc \ud3c9\uac00 \uae30\ub2a5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4(`fit()`\uacfc `evaluate()`).\n",
    "\uac1d\uccb4\uc9c0\ud5a5 \ubaa8\ub378\uc5d0\uc11c \uc774 \uae30\ub2a5\uc744 \uc0ac\uc6a9\ud558\uace0 \uc2f6\ub2e4\uba74 \uc5b8\uc81c\ub4e0\uc9c0 `Model` \ud074\ub798\uc2a4\ub97c \uc0c1\uc18d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4(`Layer`\ub97c\n",
    "\uc11c\ube0c\ud074\ub798\uc2f1\ud558\ub294 \uac83\uacfc \ub3d9\uc77c\ud558\uac8c \uc791\ub3d9\ud569\ub2c8\ub2e4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uc5d4\ub4dc-\ud22c-\uc5d4\ub4dc \uc608\uc81c 1: \ubcc0\uc774\ud615 \uc624\ud1a0\uc778\ucf54\ub354\n",
    "\n",
    "\uc9c0\uae08\uae4c\uc9c0 \ubc30\uc6b4 \ub0b4\uc6a9\uc740 \ub2e4\uc74c\uacfc \uac19\uc2b5\ub2c8\ub2e4:\n",
    "\n",
    "- `Layer`\ub294 (`__init__`\ub098 `build`\uc5d0\uc11c \ub9cc\ub4e0) \uc0c1\ud0dc\uc640 (`call`\uc5d0\uc11c \uc815\uc758\ud55c) \uacc4\uc0b0\uc744 \ucea1\uc290\ud654\ud569\ub2c8\ub2e4.\n",
    "- \uce35\uc744 \uc7ac\uadc0\uc801\uc73c\ub85c \uc911\ucca9\ud558\uc5ec \ub354 \ud070 \uc0c8\ub85c\uc6b4 \ube14\ub85d\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "- `GradientTape`\uc758 `with` \ube14\ub85d \uc548\uc5d0\uc11c \ubaa8\ub378\uc744 \ud638\ucd9c\ud558\uc5ec \ud6c8\ub828 \ubc18\ubcf5 \uacfc\uc815\uc744 \ub9c8\uc74c\uaecf \ud574\ud0b9\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uadf8\ub2e4\uc74c \uc635\ud2f0\ub9c8\uc774\uc800\ub97c \uc0ac\uc6a9\ud574 \ucd94\ucd9c\ud55c \uadf8\ub808\uc774\ub514\uc5b8\ud2b8\ub97c \uc801\uc6a9\ud569\ub2c8\ub2e4.\n",
    "- `@tf.function` \ub370\ucf54\ub808\uc774\ud130\ub97c \uc0ac\uc6a9\ud574 \ud6c8\ub828 \ubc18\ubcf5\uc758 \uc18d\ub3c4\ub97c \ub192\uc77c \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "- \uce35\uc740 `self.add_loss()`\ub97c \uc0ac\uc6a9\ud574 \uc190\uc2e4(\uc77c\ubc18\uc801\uc73c\ub85c \uaddc\uc81c \uc190\uc2e4)\uc744 \ub9cc\ub4e4\uace0 \uae30\ub85d\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\uc774\ub97c \uc0ac\uc6a9\ud574 \uc5d4\ub4dc-\ud22c-\uc5d4\ub4dc \uc608\uc81c\ub97c \ub9cc\ub4e4\uc5b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4:\n",
    "\ubcc0\uc774\ud615 \uc624\ud1a0\uc778\ucf54\ub354(Variational AutoEncoder, VAE)\ub97c \ub9cc\ub4e4\uace0 MNIST \ub370\uc774\ud130\uc14b\uc5d0\uc11c \ud6c8\ub828\ud574 \ubcf4\uc8e0.\n",
    "\n",
    "\uc774 VAE\ub294 `Layer`\uc758 \uc11c\ube0c\ud074\ub798\uc2a4\uc785\ub2c8\ub2e4.\n",
    "\ub610\ud55c `Layer`\ub97c \uc11c\ube0c\ud074\ub798\uc2f1\ud55c \uce35\uc744 \uc870\ud569\ud558\uc5ec \uad6c\uc131\ud569\ub2c8\ub2e4.\n",
    "\uaddc\uc81c \uc190\uc2e4(KL \ubc1c\uc0b0)\ub3c4 \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ubaa8\ub378\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n",
    "\n",
    "\uba3c\uc800, `Sampling` \uce35\uc744 \uc0ac\uc6a9\ud574 MNIST \uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c\n",
    "\uc7a0\uc7ac \uacf5\uac04\uc758 \uc138 \uac12 `(z_mean, z_log_var, z)`\uc5d0 \ub9e4\ud551\ud558\ub294 `Encoder` \ud074\ub798\uc2a4\ub97c \uc815\uc758\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"(z_mean, z_log_var)\ub97c \uc0ac\uc6a9\ud574 \uc22b\uc790 \uc778\ucf54\ub529 \ubca1\ud130 z\ub97c \uc0d8\ud50c\ub9c1\ud569\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "    \"\"\"MNIST \uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c (z_mean, z_log_var, z) \uc138 \uac12\uc73c\ub85c \ub9e4\ud551\ud569\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim=32, intermediate_dim=64, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=tf.nn.relu)\n",
    "        self.dense_mean = layers.Dense(latent_dim)\n",
    "        self.dense_log_var = layers.Dense(latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        return z_mean, z_log_var, z\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uadf8\ub2e4\uc74c \ud655\ub960\uc801 \uc7a0\uc7ac \uacf5\uac04\uc758 \uc88c\ud45c\ub97c MNIST \uc22b\uc790 \uc774\ubbf8\uc9c0\ub85c \ub9e4\ud551\ud558\ub294 `Decoder` \ud074\ub798\uc2a4\ub97c \uc815\uc758\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(layers.Layer):\n",
    "    \"\"\"\uc778\ucf54\ub529\ub41c \ubca1\ud130 z\ub97c \uc22b\uc790 \uc774\ubbf8\uc9c0\ub85c \ub418\ub3cc\ub9bd\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim=64, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.dense_proj = layers.Dense(intermediate_dim, activation=tf.nn.relu)\n",
    "        self.dense_output = layers.Dense(original_dim, activation=tf.nn.sigmoid)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_proj(inputs)\n",
    "        return self.dense_output(x)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ub9c8\uc9c0\ub9c9\uc73c\ub85c `VariationalAutoEncoder`\ub294 \uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\ub97c \uc5f0\uacb0\ud558\uace0\n",
    "`add_loss()` \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud574 KL \ubc1c\uc0b0 \uaddc\uc81c\ub97c \ucd94\uac00\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "class VariationalAutoEncoder(layers.Layer):\n",
    "    \"\"\"\uc778\ucf54\ub354\uc640 \ub514\ucf54\ub354\ub97c \uc5f0\uacb0\ud558\uc5ec \uc5d4\ub4dc-\ud22c-\uc5d4\ub4dc \ubaa8\ub378\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\"\"\"\n",
    "\n",
    "    def __init__(self, original_dim, intermediate_dim=64, latent_dim=32, **kwargs):\n",
    "        super(VariationalAutoEncoder, self).__init__(**kwargs)\n",
    "        self.original_dim = original_dim\n",
    "        self.encoder = Encoder(latent_dim=latent_dim, intermediate_dim=intermediate_dim)\n",
    "        self.decoder = Decoder(original_dim, intermediate_dim=intermediate_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # KL \ubc1c\uc0b0 \uaddc\uc81c \uc190\uc2e4\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4.\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1\n",
    "        )\n",
    "        self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc774\uc81c \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "\uc18d\ub3c4\ub97c \ub192\uc774\uae30 \uc704\ud574 \ud6c8\ub828 \uc2a4\ud15d\uc744 `@tf.function`\uc73c\ub85c \uac10\uc2f8\uc11c \uadf8\ub798\ud504\ub85c \ucef4\ud30c\uc77c\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \ubcc0\uc774\ud615 \uc624\ud1a0\uc778\ucf54\ub354 \ubaa8\ub378\n",
    "vae = VariationalAutoEncoder(original_dim=784, intermediate_dim=64, latent_dim=32)\n",
    "\n",
    "# \uc190\uc2e4\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    ")\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def training_step(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        reconstructed = vae(x)  # \uc785\ub825\uc758 \uc7ac\uad6c\uc131\uc744 \ub9cc\ub4ed\ub2c8\ub2e4.\n",
    "        # \uc190\uc2e4\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "        loss = loss_fn(x, reconstructed)\n",
    "        loss += sum(vae.losses)  # KL \ubc1c\uc0b0\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4.\n",
    "    # VAE\uc758 \uac00\uc911\uce58\ub97c \uc5c5\ub370\uc774\ud2b8\ud569\ub2c8\ub2e4.\n",
    "    grads = tape.gradient(loss, vae.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = []  # \uc190\uc2e4\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
    "for step, x in enumerate(dataset):\n",
    "    loss = training_step(x)\n",
    "    # \ub85c\uae45\n",
    "    losses.append(float(loss))\n",
    "    if step % 100 == 0:\n",
    "        print(\"\uc2a4\ud15d:\", step, \"\uc190\uc2e4:\", sum(losses) / len(losses))\n",
    "\n",
    "    # 1,000\ubc88 \uc2a4\ud15d \ud6c4\uc5d0 \uba48\ucda5\ub2c8\ub2e4.\n",
    "    # \uc218\ub834\ud560 \ub54c\uae4c\uc9c0 \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294 \uac83\uc740 \ub3c5\uc790\ub4e4\uc5d0\uac8c \uc219\uc81c\ub85c \ub0a8\uaca8 \ub193\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "    if step >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc5ec\uae30\uc11c \ubcfc \uc218 \uc788\ub4ef\uc774 \ucf00\ub77c\uc2a4\uc5d0\uc11c\ub294 \uc774\ub7f0 \uc885\ub958\uc758 \ubaa8\ub378\uc744 \ube60\ub974\uace0 \uac04\ub2e8\ud558\uac8c \ub9cc\ub4e4\uace0 \ud6c8\ub828\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\uc5b4\uca4c\uba74 \uc704 \ucf54\ub4dc\uac00 \uc870\uae08 \uc7a5\ud669\ud558\ub2e4\uace0 \uc0dd\uac01\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\uc0c1\uc138 \uc0ac\ud56d\uc744 \ubaa8\ub450 \uc9c1\uc811 \ub9cc\ub4e4\uc5c8\uc2b5\ub2c8\ub2e4. \uc774\ub807\uac8c \ud558\uba74 \uc720\uc5f0\uc131\uc774 \uadf9\ub300\ud654\ub418\uc9c0\ub9cc \uc791\uc5c5\uc744 \uc870\uae08 \ud574\uc57c \ud569\ub2c8\ub2e4.\n",
    "\n",
    "\ud568\uc218\ud615 API \ubc84\uc804\uc758 VAE\ub97c \uc0b4\ud3b4 \ubcf4\uc8e0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "original_dim = 784\n",
    "intermediate_dim = 64\n",
    "latent_dim = 32\n",
    "\n",
    "# \uc778\ucf54\ub354 \ubaa8\ub378\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n",
    "original_inputs = tf.keras.Input(shape=(original_dim,), name=\"encoder_input\")\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(original_inputs)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name=\"encoder\")\n",
    "\n",
    "# \ub514\ucf54\ub354 \ubaa8\ub378\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n",
    "latent_inputs = tf.keras.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "x = layers.Dense(intermediate_dim, activation=\"relu\")(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation=\"sigmoid\")(x)\n",
    "decoder = tf.keras.Model(inputs=latent_inputs, outputs=outputs, name=\"decoder\")\n",
    "\n",
    "# VAE \ubaa8\ub378\uc744 \uc815\uc758\ud569\ub2c8\ub2e4.\n",
    "outputs = decoder(z)\n",
    "vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name=\"vae\")\n",
    "\n",
    "# KL \ubc1c\uc0b0 \uaddc\uc81c \uc190\uc2e4\uc744 \ucd94\uac00\ud569\ub2c8\ub2e4.\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae.add_loss(kl_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ud6e8\uc52c \uac04\uc18c\ud558\uc9c0 \uc54a\ub098\uc694?\n",
    "\n",
    "\uc774 \uacbd\uc6b0\uc5d0\ub3c4 \ucf00\ub77c\uc2a4\ub294 `Model` \ud074\ub798\uc2a4\uc5d0 \uae30\ubcf8\uc801\uc73c\ub85c \ud6c8\ub828 & \ud3c9\uac00 \ubc18\ubcf5\uc744 \uc81c\uacf5\ud569\ub2c8\ub2e4(`fit()`\uacfc `evaluate()`).\n",
    "\ud655\uc778\ud574 \ubcf4\uc8e0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uc190\uc2e4\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, _), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    ")\n",
    "dataset = dataset.map(lambda x: (x, x))  # \uc785\ub825\uacfc \ud0c0\uae43\uc73c\ub85c x_train\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4.\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "# \ud6c8\ub828\uc744 \uc704\ud574 \ubaa8\ub378\uc744 \uc124\uc815\ud569\ub2c8\ub2e4.\n",
    "vae.compile(optimizer, loss=loss_fn)\n",
    "\n",
    "# \ubaa8\ub378\uc744 \ud6c8\ub828\ud569\ub2c8\ub2e4.\n",
    "vae.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ud568\uc218\ud615 API\uc640 `fit` \uba54\uc11c\ub4dc\ub97c \uc0ac\uc6a9\ud558\uc5ec 65\uc904\uc758 \ucf54\ub4dc\ub97c 25\uc904\ub85c \uc904\uc600\uc2b5\ub2c8\ub2e4(\ubaa8\ub378 \uc815\uc758\uc640 \ud6c8\ub828\uc744 \ud3ec\ud568\ud588\uc2b5\ub2c8\ub2e4).\n",
    "\ucf00\ub77c\uc2a4\uc758 \ucca0\ud559\uc740 \uc774\ub807\uac8c \uc0dd\uc0b0\uc131\uc744 \ub192\uc77c \uc218 \uc788\ub294 \uae30\ub2a5\uc744 \uc81c\uacf5\ud558\ub294 \uac83\uc785\ub2c8\ub2e4.\n",
    "\ub3d9\uc2dc\uc5d0 \ubaa8\ub4e0 \uac83\uc744 \uc9c1\uc811 \ub9cc\ub4e4\uc5b4 \uc0c1\uc138 \ub0b4\uc6a9\uc744 \uc644\ubcbd\ud788 \uc81c\uc5b4\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n",
    "\ub450 \ubb38\ub2e8 \uc55e\uc5d0\uc11c \ub9cc\ub4e4\uc5c8\ub358 \uc800\uc218\uc900 \ud6c8\ub828 \ubc18\ubcf5\ubb38\uc744 \ucc38\uace0\ud558\uc138\uc694."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## \uc5d4\ub4dc-\ud22c-\uc5d4\ub4dc \uc608\uc81c 2: \ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c\n",
    "\n",
    "\ub2e4\ub978 \uc885\ub958\uc758 \uc5d0\uc81c\uc778 \ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c(hypernetwork)\ub97c \uc0b4\ud3b4 \ubcf4\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "\n",
    "\ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c\ub294 \uac00\uc911\uce58\uac00 (\uc77c\ubc18\uc801\uc73c\ub85c \ub354 \uc791\uc740) \ub2e4\ub978 \uc2e0\uacbd\ub9dd\uc5d0 \uc758\ud574 \uc0dd\uc131\ub418\ub294 \uc2ec\uce35 \uc2e0\uacbd\ub9dd\uc785\ub2c8\ub2e4.\n",
    "\n",
    "\uc544\uc8fc \uc791\uc740 \ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c\ub97c \ub9cc\ub4e4\uc5b4 \ubcf4\uc8e0.\n",
    "2\uac1c\uc758 \uce35\uc744 \uac00\uc9c4 \uc2e0\uacbd\ub9dd\uc744 \uc0ac\uc6a9\ud574 3\uac1c\uc758 \uce35\uc744 \uac00\uc9c4 \uc2e0\uacbd\ub9dd\uc758 \uac00\uc911\uce58\ub97c \uc0dd\uc131\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_dim = 784\n",
    "classes = 10\n",
    "\n",
    "# \ub808\uc774\ube14\uc744 \uc608\uce21\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9\ud560 \ubaa8\ub378\uc785\ub2c8\ub2e4(\ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c).\n",
    "outer_model = keras.Sequential(\n",
    "    [keras.layers.Dense(64, activation=tf.nn.relu), keras.layers.Dense(classes),]\n",
    ")\n",
    "\n",
    "# \uac00\uc911\uce58\ub97c \ub9cc\ub4e4 \ud544\uc694\uac00 \uc5c6\uc73c\ubbc0\ub85c \ubbf8\ub9ac \ub9cc\ub4e4\uc5b4\uc84c\ub2e4\uace0 \uce35\uc744 \uc124\uc815\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "# \uc774\ub807\uac8c \ud558\uba74 `outer_model`\uc774 \uc0c8\ub85c\uc6b4 \ubcc0\uc218\ub97c \ub9cc\ub4e4\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4.\n",
    "for layer in outer_model.layers:\n",
    "    layer.built = True\n",
    "\n",
    "# \uc0dd\uc131\ud560 \uac00\uc911\uce58 \uac1c\uc218\uc785\ub2c8\ub2e4.\n",
    "# \ud558\uc774\ud37c\ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc788\ub294 \uce35\ub9c8\ub2e4 output_dim * input_dim + output_dim\uac1c\uc758 \uac00\uc911\uce58\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n",
    "num_weights_to_generate = (classes * 64 + classes) + (64 * input_dim + 64)\n",
    "\n",
    "# `outer_model` \ubaa8\ub378\uc758 \uac00\uc911\uce58\ub97c \uc0dd\uc131\ud558\ub294 \ubaa8\ub378\uc785\ub2c8\ub2e4.\n",
    "inner_model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "        keras.layers.Dense(num_weights_to_generate, activation=tf.nn.sigmoid),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ud6c8\ub828 \ubc18\ubcf5\uc744 \uad6c\ud604\ud569\ub2c8\ub2e4. \ubc30\uce58 \ub370\uc774\ud130\uc5d0 \ub300\ud574 \ub2e4\uc74c\uc744 \uc218\ud589\ud569\ub2c8\ub2e4:\n",
    "\n",
    "- `inner_model`\uc744 \uc0ac\uc6a9\ud574 `weights_pred` \uac00\uc911\uce58 \ubc30\uc5f4\uc744 \uc0dd\uc131\ud569\ub2c8\ub2e4.\n",
    "- \uc774 \uac00\uc911\uce58\ub97c `outer_model`\uc758 \ucee4\ub110\uacfc \ud3b8\ud5a5 \ud150\uc11c\ub85c \ubc14\uafc9\ub2c8\ub2e4.\n",
    "- `outer_model`\uc758 \uc815\ubc29\ud5a5 \uacc4\uc0b0\uc744 \uc2e4\ud589\ud558\uc5ec MNIST \ub370\uc774\ud130\uc5d0 \ub300\ud55c \uc608\uce21\uc744 \uacc4\uc0b0\ud569\ub2c8\ub2e4.\n",
    "- `inner_model`\uc758 \uac00\uc911\uce58\ub85c \uc5ed\uc804\ud30c\ud558\uc5ec \ucd5c\uc885 \ubd84\ub958 \uc190\uc2e4\uc744 \ucd5c\uc18c\ud654\ud569\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# \uc190\uc2e4\uacfc \uc635\ud2f0\ub9c8\uc774\uc800\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "# \ub370\uc774\ud130\uc14b\uc744 \uc900\ube44\ud569\ub2c8\ub2e4.\n",
    "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape(60000, 784).astype(\"float32\") / 255, y_train)\n",
    ")\n",
    "\n",
    "# \uc2e4\ud5d8\uc744 \uc704\ud574 \ubc30\uce58 \ud06c\uae30 1\uc744 \uc0ac\uc6a9\ud558\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(1)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # outer_model\uc758 \uac00\uc911\uce58\ub97c \uc608\uce21\ud569\ub2c8\ub2e4.\n",
    "        weights_pred = inner_model(x)\n",
    "\n",
    "        # outer_model\uc758 w\uc640 b\uc758 \ud06c\uae30\uc5d0 \ub9de\uac8c \ubc14\uafc9\ub2c8\ub2e4.\n",
    "        # \uccab \ubc88\uc9f8 \uce35\uc758 \ucee4\ub110\n",
    "        start_index = 0\n",
    "        w0_shape = (input_dim, 64)\n",
    "        w0_coeffs = weights_pred[:, start_index : start_index + np.prod(w0_shape)]\n",
    "        w0 = tf.reshape(w0_coeffs, w0_shape)\n",
    "        start_index += np.prod(w0_shape)\n",
    "        # \uccab \ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5\n",
    "        b0_shape = (64,)\n",
    "        b0_coeffs = weights_pred[:, start_index : start_index + np.prod(b0_shape)]\n",
    "        b0 = tf.reshape(b0_coeffs, b0_shape)\n",
    "        start_index += np.prod(b0_shape)\n",
    "        # \ub450 \ubc88\uc9f8 \uce35\uc758 \ucee4\ub110\n",
    "        w1_shape = (64, classes)\n",
    "        w1_coeffs = weights_pred[:, start_index : start_index + np.prod(w1_shape)]\n",
    "        w1 = tf.reshape(w1_coeffs, w1_shape)\n",
    "        start_index += np.prod(w1_shape)\n",
    "        # \uccab \ubc88\uc9f8 \uce35\uc758 \ud3b8\ud5a5\n",
    "        b1_shape = (classes,)\n",
    "        b1_coeffs = weights_pred[:, start_index : start_index + np.prod(b1_shape)]\n",
    "        b1 = tf.reshape(b1_coeffs, b1_shape)\n",
    "        start_index += np.prod(b1_shape)\n",
    "\n",
    "        # outer_model\uc758 \uac00\uc911\uce58 \ubcc0\uc218\ub85c \uc124\uc815\ud569\ub2c8\ub2e4.\n",
    "        outer_model.layers[0].kernel = w0\n",
    "        outer_model.layers[0].bias = b0\n",
    "        outer_model.layers[1].kernel = w1\n",
    "        outer_model.layers[1].bias = b1\n",
    "\n",
    "        # outer_model\uc758 \ucd94\ub860\uc744 \uc218\ud589\ud569\ub2c8\ub2e4.\n",
    "        preds = outer_model(x)\n",
    "        loss = loss_fn(y, preds)\n",
    "\n",
    "    # inner_model\ub9cc \ud6c8\ub828\ud569\ub2c8\ub2e4.\n",
    "    grads = tape.gradient(loss, inner_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, inner_model.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "\n",
    "losses = []  # \uc190\uc2e4\uc744 \uae30\ub85d\ud569\ub2c8\ub2e4.\n",
    "for step, (x, y) in enumerate(dataset):\n",
    "    loss = train_step(x, y)\n",
    "\n",
    "    # \ub85c\uae45\n",
    "    losses.append(float(loss))\n",
    "    if step % 100 == 0:\n",
    "        print(\"\uc2a4\ud15d:\", step, \"\uc190\uc2e4:\", sum(losses) / len(losses))\n",
    "\n",
    "    # 1,000\ubc88 \uc2a4\ud15d \ud6c4\uc5d0 \uba48\ucda5\ub2c8\ub2e4.\n",
    "    # \uc218\ub834\ud560 \ub54c\uae4c\uc9c0 \ubaa8\ub378\uc744 \ud6c8\ub828\ud558\ub294 \uac83\uc740 \ub3c5\uc790\ub4e4\uc5d0\uac8c \uc219\uc81c\ub85c \ub0a8\uaca8 \ub193\uaca0\uc2b5\ub2c8\ub2e4.\n",
    "    if step >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\ucf00\ub77c\uc2a4\ub85c \uc5b4\ub5a4 \uc5f0\uad6c \uc544\uc774\ub514\uc5b4\ub97c \uad6c\ud604\ud558\ub354\ub77c\ub3c4 \uc27d\uace0 \ub9e4\uc6b0 \uc0dd\uc0b0\uc801\uc785\ub2c8\ub2e4.\n",
    "\ud558\ub8e8\uc5d0 25\uac1c\uc758 \uc544\uc774\ub514\uc5b4\ub97c \uc2e4\ud5d8\ud574 \ubcf4\uc138\uc694(\ud3c9\uade0\uc801\uc73c\ub85c \uc2e4\ud5d8\ub2f9 20\ubd84\uc785\ub2c8\ub2e4)!\n",
    "\n",
    "\ucf00\ub77c\uc2a4\ub294 \uac00\ub2a5\ud55c \ube60\ub974\uac8c \uc544\uc774\ub514\uc5b4\uc5d0\uc11c \uacb0\uacfc\ub97c \ub9cc\ub4e4 \uc218 \uc788\ub3c4\ub85d \uc124\uacc4\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n",
    "\uc774\uac83\uc774 \uc704\ub300\ud55c \uc5f0\uad6c\ub97c \uc218\ud589\ud558\ub294 \ud575\uc2ec \uc5f4\uc1e0\ub77c\uace0 \ubbff\uae30 \ub54c\ubb38\uc785\ub2c8\ub2e4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "\uc774 \uac00\uc774\ub4dc\uac00 \ub3c4\uc6c0\uc774 \ub418\uc5c8\uae30\ub97c \ubc14\ub78d\ub2c8\ub2e4. \ucf00\ub77c\uc2a4\ub85c \ubb34\uc5b8\uac00 \ub9cc\ub4e4\uc5c8\ub2e4\uba74 \uc54c\ub824\uc8fc\uc138\uc694!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro_to_keras_for_researchers",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}